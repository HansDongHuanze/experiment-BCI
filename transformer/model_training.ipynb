{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24dd68f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT(\n",
      "  (to_patch_embedding): Sequential(\n",
      "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=32, p2=1)\n",
      "    (1): Linear(in_features=96, out_features=1024, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (transformer): Transformer(\n",
      "    (layers): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=8, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Linear(in_features=8, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=8, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Linear(in_features=8, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=8, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Linear(in_features=8, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=8, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Linear(in_features=8, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=8, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Linear(in_features=8, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=8, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Linear(in_features=8, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (to_latent): Identity()\n",
      "  (mlp_head): Sequential(\n",
      "    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=1024, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from vit_pytorch import ViT\n",
    "\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "\n",
    "\n",
    "model = ViT(\n",
    "    image_size = 512,    # 图像大小\n",
    "    patch_size = 32,     # patch大小（分块的大小）\n",
    "    num_classes = 4,  # imagenet数据集1000分类\n",
    "    dim = 1024,          # position embedding的维度\n",
    "    depth = 6,           # encoder和decoder中block层数是6\n",
    "    heads = 16,          # multi-head中head的数量为16\n",
    "    mlp_dim = 8,\n",
    "    dropout = 0.1,       # \n",
    "    emb_dropout = 0.1\n",
    ")\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "# img = torch.randn(1, 3, 256, 1)\n",
    "\n",
    "# preds = model(img) # (1, 1000)\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
    "print(model)  # (16, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a19636a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from data_extractor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13be733c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<data_extractor.Extractor at 0x7f71d9c67460>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Extractor('A01T')\n",
    "Extractor('A02T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f451c892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhz/experiment-BCI/transformer/../data_extractor.py:125: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  return torch.tensor(labels), torch.tensor(data)\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_eeg('A01T')\n",
    "labels, train_data = data_normalization(raw_data)\n",
    "raw_data_eva = load_eeg('A02T')\n",
    "labels_eva, eva_data = data_normalization(raw_data_eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f7d485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of labels is: torch.Size([288, 4]) shape of data is: torch.Size([288, 3, 512, 1])\n",
      "shape of labels is: torch.Size([288, 4]) shape of data is: torch.Size([288, 3, 512, 1])\n"
     ]
    }
   ],
   "source": [
    "print('shape of labels is:', labels.shape, 'shape of data is:', train_data.shape)\n",
    "print('shape of labels is:', labels_eva.shape, 'shape of data is:', eva_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "183982c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pres = model(train_data.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab29c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef560a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    # 构造函数\n",
    "    def __init__(self, data_tensor, target_tensor):\n",
    "        self.data_tensor = data_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "    # 返回数据集大小\n",
    "    def __len__(self):\n",
    "        return self.data_tensor.size(0)\n",
    "    # 返回索引的数据与标签\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_tensor[index], self.target_tensor[index]\n",
    "    \n",
    "dataset = MyDataset(train_data, labels)\n",
    "BATCH_SIZE = 32\n",
    "data_loader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "dataset_eva = MyDataset(eva_data, labels_eva)\n",
    "data_loader_eva = DataLoader(dataset_eva, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "673c06aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch(Training) [1/100]: 100% 9/9 [00:01<00:00,  4.85batch/s, loss=3.49]\n",
      "Epoch(Evaluation) [1/100]: 100% 9/9 [00:00<00:00, 11.29batch/s, acc=1]    \n",
      "Epoch(Training) [2/100]: 100% 9/9 [00:01<00:00,  4.91batch/s, loss=0.556]\n",
      "Epoch(Evaluation) [2/100]: 100% 9/9 [00:00<00:00, 11.44batch/s, acc=1]    \n",
      "Epoch(Training) [3/100]: 100% 9/9 [00:01<00:00,  4.87batch/s, loss=0.317] \n",
      "Epoch(Evaluation) [3/100]: 100% 9/9 [00:00<00:00, 11.05batch/s, acc=1]    \n",
      "Epoch(Training) [4/100]: 100% 9/9 [00:01<00:00,  4.86batch/s, loss=0.229] \n",
      "Epoch(Evaluation) [4/100]: 100% 9/9 [00:00<00:00, 11.28batch/s, acc=1]    \n",
      "Epoch(Training) [5/100]: 100% 9/9 [00:01<00:00,  5.00batch/s, loss=0.17]  \n",
      "Epoch(Evaluation) [5/100]: 100% 9/9 [00:00<00:00, 10.93batch/s, acc=1]    \n",
      "Epoch(Training) [6/100]: 100% 9/9 [00:01<00:00,  4.86batch/s, loss=0.14]  \n",
      "Epoch(Evaluation) [6/100]: 100% 9/9 [00:00<00:00, 11.00batch/s, acc=1]    \n",
      "Epoch(Training) [7/100]: 100% 9/9 [00:01<00:00,  4.81batch/s, loss=0.117] \n",
      "Epoch(Evaluation) [7/100]: 100% 9/9 [00:00<00:00, 11.12batch/s, acc=1]    \n",
      "Epoch(Training) [8/100]: 100% 9/9 [00:01<00:00,  4.96batch/s, loss=0.105] \n",
      "Epoch(Evaluation) [8/100]: 100% 9/9 [00:00<00:00, 11.01batch/s, acc=1]    \n",
      "Epoch(Training) [9/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.0921]\n",
      "Epoch(Evaluation) [9/100]: 100% 9/9 [00:00<00:00, 10.98batch/s, acc=1]    \n",
      "Epoch(Training) [10/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.0808]\n",
      "Epoch(Evaluation) [10/100]: 100% 9/9 [00:00<00:00, 11.17batch/s, acc=1]    \n",
      "Epoch(Training) [11/100]: 100% 9/9 [00:01<00:00,  4.85batch/s, loss=0.0725]\n",
      "Epoch(Evaluation) [11/100]: 100% 9/9 [00:00<00:00, 11.56batch/s, acc=1]    \n",
      "Epoch(Training) [12/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.0668] \n",
      "Epoch(Evaluation) [12/100]: 100% 9/9 [00:00<00:00, 10.87batch/s, acc=1]    \n",
      "Epoch(Training) [13/100]: 100% 9/9 [00:01<00:00,  4.82batch/s, loss=0.0599]\n",
      "Epoch(Evaluation) [13/100]: 100% 9/9 [00:00<00:00, 10.95batch/s, acc=1]    \n",
      "Epoch(Training) [14/100]: 100% 9/9 [00:01<00:00,  4.87batch/s, loss=0.057] \n",
      "Epoch(Evaluation) [14/100]: 100% 9/9 [00:00<00:00, 11.50batch/s, acc=1]    \n",
      "Epoch(Training) [15/100]: 100% 9/9 [00:01<00:00,  4.82batch/s, loss=0.052]  \n",
      "Epoch(Evaluation) [15/100]: 100% 9/9 [00:00<00:00, 10.90batch/s, acc=1]    \n",
      "Epoch(Training) [16/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.0486]\n",
      "Epoch(Evaluation) [16/100]: 100% 9/9 [00:00<00:00, 11.15batch/s, acc=1]    \n",
      "Epoch(Training) [17/100]: 100% 9/9 [00:01<00:00,  4.89batch/s, loss=0.0469]\n",
      "Epoch(Evaluation) [17/100]: 100% 9/9 [00:00<00:00, 11.36batch/s, acc=1]    \n",
      "Epoch(Training) [18/100]: 100% 9/9 [00:01<00:00,  4.82batch/s, loss=0.043] \n",
      "Epoch(Evaluation) [18/100]: 100% 9/9 [00:00<00:00, 10.90batch/s, acc=1]    \n",
      "Epoch(Training) [19/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.041]  \n",
      "Epoch(Evaluation) [19/100]: 100% 9/9 [00:00<00:00, 11.02batch/s, acc=1]    \n",
      "Epoch(Training) [20/100]: 100% 9/9 [00:01<00:00,  4.90batch/s, loss=0.04]   \n",
      "Epoch(Evaluation) [20/100]: 100% 9/9 [00:00<00:00, 11.39batch/s, acc=1]    \n",
      "Epoch(Training) [21/100]: 100% 9/9 [00:01<00:00,  4.81batch/s, loss=0.0374] \n",
      "Epoch(Evaluation) [21/100]: 100% 9/9 [00:00<00:00, 10.85batch/s, acc=1]    \n",
      "Epoch(Training) [22/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.0351] \n",
      "Epoch(Evaluation) [22/100]: 100% 9/9 [00:00<00:00, 10.97batch/s, acc=1]    \n",
      "Epoch(Training) [23/100]: 100% 9/9 [00:01<00:00,  4.86batch/s, loss=0.0332]\n",
      "Epoch(Evaluation) [23/100]: 100% 9/9 [00:00<00:00, 11.49batch/s, acc=1]    \n",
      "Epoch(Training) [24/100]: 100% 9/9 [00:01<00:00,  4.81batch/s, loss=0.0315] \n",
      "Epoch(Evaluation) [24/100]: 100% 9/9 [00:00<00:00, 10.91batch/s, acc=1]    \n",
      "Epoch(Training) [25/100]: 100% 9/9 [00:01<00:00,  4.81batch/s, loss=0.0311] \n",
      "Epoch(Evaluation) [25/100]: 100% 9/9 [00:00<00:00, 11.28batch/s, acc=1]    \n",
      "Epoch(Training) [26/100]: 100% 9/9 [00:01<00:00,  4.93batch/s, loss=0.0301] \n",
      "Epoch(Evaluation) [26/100]: 100% 9/9 [00:00<00:00, 10.84batch/s, acc=1]    \n",
      "Epoch(Training) [27/100]: 100% 9/9 [00:01<00:00,  4.81batch/s, loss=0.0276] \n",
      "Epoch(Evaluation) [27/100]: 100% 9/9 [00:00<00:00, 10.99batch/s, acc=1]    \n",
      "Epoch(Training) [28/100]: 100% 9/9 [00:01<00:00,  4.88batch/s, loss=0.0283] \n",
      "Epoch(Evaluation) [28/100]: 100% 9/9 [00:00<00:00, 11.38batch/s, acc=1]    \n",
      "Epoch(Training) [29/100]: 100% 9/9 [00:01<00:00,  4.80batch/s, loss=0.0279] \n",
      "Epoch(Evaluation) [29/100]: 100% 9/9 [00:00<00:00, 10.94batch/s, acc=1]    \n",
      "Epoch(Training) [30/100]: 100% 9/9 [00:01<00:00,  4.86batch/s, loss=0.0256] \n",
      "Epoch(Evaluation) [30/100]: 100% 9/9 [00:00<00:00, 11.46batch/s, acc=1]    \n",
      "Epoch(Training) [31/100]: 100% 9/9 [00:01<00:00,  4.80batch/s, loss=0.0251] \n",
      "Epoch(Evaluation) [31/100]: 100% 9/9 [00:00<00:00, 10.94batch/s, acc=1]    \n",
      "Epoch(Training) [32/100]: 100% 9/9 [00:01<00:00,  4.85batch/s, loss=0.0242] \n",
      "Epoch(Evaluation) [32/100]: 100% 9/9 [00:00<00:00, 11.47batch/s, acc=1]    \n",
      "Epoch(Training) [33/100]: 100% 9/9 [00:01<00:00,  4.80batch/s, loss=0.0233] \n",
      "Epoch(Evaluation) [33/100]: 100% 9/9 [00:00<00:00, 10.90batch/s, acc=1]    \n",
      "Epoch(Training) [34/100]: 100% 9/9 [00:01<00:00,  4.80batch/s, loss=0.0229] \n",
      "Epoch(Evaluation) [34/100]: 100% 9/9 [00:00<00:00, 11.66batch/s, acc=1]    \n",
      "Epoch(Training) [35/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.022]  \n",
      "Epoch(Evaluation) [35/100]: 100% 9/9 [00:00<00:00, 10.80batch/s, acc=1]    \n",
      "Epoch(Training) [36/100]: 100% 9/9 [00:01<00:00,  4.82batch/s, loss=0.0218] \n",
      "Epoch(Evaluation) [36/100]: 100% 9/9 [00:00<00:00, 11.06batch/s, acc=1]    \n",
      "Epoch(Training) [37/100]: 100% 9/9 [00:01<00:00,  4.91batch/s, loss=0.0203] \n",
      "Epoch(Evaluation) [37/100]: 100% 9/9 [00:00<00:00, 11.07batch/s, acc=1]    \n",
      "Epoch(Training) [38/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.0202] \n",
      "Epoch(Evaluation) [38/100]: 100% 9/9 [00:00<00:00, 10.93batch/s, acc=1]    \n",
      "Epoch(Training) [39/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.0207] \n",
      "Epoch(Evaluation) [39/100]: 100% 9/9 [00:00<00:00, 11.59batch/s, acc=1]    \n",
      "Epoch(Training) [40/100]: 100% 9/9 [00:01<00:00,  4.82batch/s, loss=0.0193] \n",
      "Epoch(Evaluation) [40/100]: 100% 9/9 [00:00<00:00, 10.96batch/s, acc=1]    \n",
      "Epoch(Training) [41/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.0189] \n",
      "Epoch(Evaluation) [41/100]: 100% 9/9 [00:00<00:00, 11.11batch/s, acc=1]    \n",
      "Epoch(Training) [42/100]: 100% 9/9 [00:01<00:00,  4.86batch/s, loss=0.0181] \n",
      "Epoch(Evaluation) [42/100]: 100% 9/9 [00:00<00:00, 11.47batch/s, acc=1]    \n",
      "Epoch(Training) [43/100]: 100% 9/9 [00:01<00:00,  4.82batch/s, loss=0.0178] \n",
      "Epoch(Evaluation) [43/100]: 100% 9/9 [00:00<00:00, 10.93batch/s, acc=1]    \n",
      "Epoch(Training) [44/100]: 100% 9/9 [00:01<00:00,  4.82batch/s, loss=0.0177] \n",
      "Epoch(Evaluation) [44/100]: 100% 9/9 [00:00<00:00, 11.27batch/s, acc=1]    \n",
      "Epoch(Training) [45/100]: 100% 9/9 [00:01<00:00,  4.92batch/s, loss=0.017]  \n",
      "Epoch(Evaluation) [45/100]: 100% 9/9 [00:00<00:00, 11.04batch/s, acc=1]    \n",
      "Epoch(Training) [46/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.0165] \n",
      "Epoch(Evaluation) [46/100]: 100% 9/9 [00:00<00:00, 10.96batch/s, acc=1]    \n",
      "Epoch(Training) [47/100]: 100% 9/9 [00:01<00:00,  4.86batch/s, loss=0.0166] \n",
      "Epoch(Evaluation) [47/100]: 100% 9/9 [00:00<00:00, 11.56batch/s, acc=1]    \n",
      "Epoch(Training) [48/100]: 100% 9/9 [00:01<00:00,  4.82batch/s, loss=0.0163] \n",
      "Epoch(Evaluation) [48/100]: 100% 9/9 [00:00<00:00, 10.89batch/s, acc=1]    \n",
      "Epoch(Training) [49/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.016]  \n",
      "Epoch(Evaluation) [49/100]: 100% 9/9 [00:00<00:00, 11.02batch/s, acc=1]    \n",
      "Epoch(Training) [50/100]: 100% 9/9 [00:01<00:00,  4.87batch/s, loss=0.0155] \n",
      "Epoch(Evaluation) [50/100]: 100% 9/9 [00:00<00:00, 11.57batch/s, acc=1]    \n",
      "Epoch(Training) [51/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.0152] \n",
      "Epoch(Evaluation) [51/100]: 100% 9/9 [00:00<00:00, 10.95batch/s, acc=1]    \n",
      "Epoch(Training) [52/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.015]  \n",
      "Epoch(Evaluation) [52/100]: 100% 9/9 [00:00<00:00, 10.98batch/s, acc=1]    \n",
      "Epoch(Training) [53/100]: 100% 9/9 [00:01<00:00,  4.88batch/s, loss=0.015]  \n",
      "Epoch(Evaluation) [53/100]: 100% 9/9 [00:00<00:00, 11.54batch/s, acc=1]    \n",
      "Epoch(Training) [54/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.0146] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch(Evaluation) [54/100]: 100% 9/9 [00:00<00:00, 10.91batch/s, acc=1]    \n",
      "Epoch(Training) [55/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.0144] \n",
      "Epoch(Evaluation) [55/100]: 100% 9/9 [00:00<00:00, 11.28batch/s, acc=1]    \n",
      "Epoch(Training) [56/100]: 100% 9/9 [00:01<00:00,  4.95batch/s, loss=0.0138] \n",
      "Epoch(Evaluation) [56/100]: 100% 9/9 [00:00<00:00, 10.89batch/s, acc=1]    \n",
      "Epoch(Training) [57/100]: 100% 9/9 [00:01<00:00,  4.85batch/s, loss=0.0137] \n",
      "Epoch(Evaluation) [57/100]: 100% 9/9 [00:00<00:00, 10.93batch/s, acc=1]    \n",
      "Epoch(Training) [58/100]: 100% 9/9 [00:01<00:00,  4.85batch/s, loss=0.0132] \n",
      "Epoch(Evaluation) [58/100]: 100% 9/9 [00:00<00:00, 11.77batch/s, acc=1]    \n",
      "Epoch(Training) [59/100]: 100% 9/9 [00:01<00:00,  4.86batch/s, loss=0.0131] \n",
      "Epoch(Evaluation) [59/100]: 100% 9/9 [00:00<00:00, 10.80batch/s, acc=1]    \n",
      "Epoch(Training) [60/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.0131] \n",
      "Epoch(Evaluation) [60/100]: 100% 9/9 [00:00<00:00, 10.97batch/s, acc=1]    \n",
      "Epoch(Training) [61/100]: 100% 9/9 [00:01<00:00,  4.87batch/s, loss=0.0126] \n",
      "Epoch(Evaluation) [61/100]: 100% 9/9 [00:00<00:00, 11.59batch/s, acc=1]    \n",
      "Epoch(Training) [62/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.0128] \n",
      "Epoch(Evaluation) [62/100]: 100% 9/9 [00:00<00:00, 10.90batch/s, acc=1]    \n",
      "Epoch(Training) [63/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.0122] \n",
      "Epoch(Evaluation) [63/100]: 100% 9/9 [00:00<00:00, 10.97batch/s, acc=1]    \n",
      "Epoch(Training) [64/100]: 100% 9/9 [00:01<00:00,  4.90batch/s, loss=0.0121] \n",
      "Epoch(Evaluation) [64/100]: 100% 9/9 [00:00<00:00, 11.52batch/s, acc=1]    \n",
      "Epoch(Training) [65/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.0119] \n",
      "Epoch(Evaluation) [65/100]: 100% 9/9 [00:00<00:00, 10.94batch/s, acc=1]    \n",
      "Epoch(Training) [66/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.0114] \n",
      "Epoch(Evaluation) [66/100]: 100% 9/9 [00:00<00:00, 10.96batch/s, acc=1]    \n",
      "Epoch(Training) [67/100]: 100% 9/9 [00:01<00:00,  4.89batch/s, loss=0.0117] \n",
      "Epoch(Evaluation) [67/100]: 100% 9/9 [00:00<00:00, 11.48batch/s, acc=1]    \n",
      "Epoch(Training) [68/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.0115] \n",
      "Epoch(Evaluation) [68/100]: 100% 9/9 [00:00<00:00, 10.99batch/s, acc=1]    \n",
      "Epoch(Training) [69/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.0113] \n",
      "Epoch(Evaluation) [69/100]: 100% 9/9 [00:00<00:00, 11.04batch/s, acc=1]    \n",
      "Epoch(Training) [70/100]: 100% 9/9 [00:01<00:00,  4.88batch/s, loss=0.0107] \n",
      "Epoch(Evaluation) [70/100]: 100% 9/9 [00:00<00:00, 11.52batch/s, acc=1]    \n",
      "Epoch(Training) [71/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.0109] \n",
      "Epoch(Evaluation) [71/100]: 100% 9/9 [00:00<00:00, 10.87batch/s, acc=1]    \n",
      "Epoch(Training) [72/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.0107] \n",
      "Epoch(Evaluation) [72/100]: 100% 9/9 [00:00<00:00, 11.20batch/s, acc=1]    \n",
      "Epoch(Training) [73/100]: 100% 9/9 [00:01<00:00,  4.91batch/s, loss=0.0106] \n",
      "Epoch(Evaluation) [73/100]: 100% 9/9 [00:00<00:00, 11.19batch/s, acc=1]    \n",
      "Epoch(Training) [74/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.0105] \n",
      "Epoch(Evaluation) [74/100]: 100% 9/9 [00:00<00:00, 11.02batch/s, acc=1]    \n",
      "Epoch(Training) [75/100]: 100% 9/9 [00:01<00:00,  4.82batch/s, loss=0.01]   \n",
      "Epoch(Evaluation) [75/100]: 100% 9/9 [00:00<00:00, 11.09batch/s, acc=1]    \n",
      "Epoch(Training) [76/100]: 100% 9/9 [00:01<00:00,  4.92batch/s, loss=0.0102] \n",
      "Epoch(Evaluation) [76/100]: 100% 9/9 [00:00<00:00, 11.45batch/s, acc=1]    \n",
      "Epoch(Training) [77/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.0102] \n",
      "Epoch(Evaluation) [77/100]: 100% 9/9 [00:00<00:00, 10.89batch/s, acc=1]    \n",
      "Epoch(Training) [78/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.00954]\n",
      "Epoch(Evaluation) [78/100]: 100% 9/9 [00:00<00:00, 11.03batch/s, acc=1]    \n",
      "Epoch(Training) [79/100]: 100% 9/9 [00:01<00:00,  4.85batch/s, loss=0.00974]\n",
      "Epoch(Evaluation) [79/100]: 100% 9/9 [00:00<00:00, 11.65batch/s, acc=1]    \n",
      "Epoch(Training) [80/100]: 100% 9/9 [00:01<00:00,  4.89batch/s, loss=0.00983]\n",
      "Epoch(Evaluation) [80/100]: 100% 9/9 [00:00<00:00, 10.87batch/s, acc=1]    \n",
      "Epoch(Training) [81/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.00947]\n",
      "Epoch(Evaluation) [81/100]: 100% 9/9 [00:00<00:00, 10.98batch/s, acc=1]    \n",
      "Epoch(Training) [82/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.00935]\n",
      "Epoch(Evaluation) [82/100]: 100% 9/9 [00:00<00:00, 11.20batch/s, acc=1]    \n",
      "Epoch(Training) [83/100]: 100% 9/9 [00:01<00:00,  4.85batch/s, loss=0.00943]\n",
      "Epoch(Evaluation) [83/100]: 100% 9/9 [00:00<00:00, 11.61batch/s, acc=1]    \n",
      "Epoch(Training) [84/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.00907]\n",
      "Epoch(Evaluation) [84/100]: 100% 9/9 [00:00<00:00, 10.90batch/s, acc=1]    \n",
      "Epoch(Training) [85/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.00866]\n",
      "Epoch(Evaluation) [85/100]: 100% 9/9 [00:00<00:00, 10.89batch/s, acc=1]    \n",
      "Epoch(Training) [86/100]: 100% 9/9 [00:01<00:00,  4.86batch/s, loss=0.00912]\n",
      "Epoch(Evaluation) [86/100]: 100% 9/9 [00:00<00:00, 11.71batch/s, acc=1]    \n",
      "Epoch(Training) [87/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.00906]\n",
      "Epoch(Evaluation) [87/100]: 100% 9/9 [00:00<00:00, 10.92batch/s, acc=1]    \n",
      "Epoch(Training) [88/100]: 100% 9/9 [00:01<00:00,  4.85batch/s, loss=0.00883]\n",
      "Epoch(Evaluation) [88/100]: 100% 9/9 [00:00<00:00, 10.92batch/s, acc=1]    \n",
      "Epoch(Training) [89/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.00861]\n",
      "Epoch(Evaluation) [89/100]: 100% 9/9 [00:00<00:00, 11.17batch/s, acc=1]    \n",
      "Epoch(Training) [90/100]: 100% 9/9 [00:01<00:00,  4.87batch/s, loss=0.00854]\n",
      "Epoch(Evaluation) [90/100]: 100% 9/9 [00:00<00:00, 11.43batch/s, acc=1]    \n",
      "Epoch(Training) [91/100]: 100% 9/9 [00:01<00:00,  4.86batch/s, loss=0.00842] \n",
      "Epoch(Evaluation) [91/100]: 100% 9/9 [00:00<00:00, 10.85batch/s, acc=1]    \n",
      "Epoch(Training) [92/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.00828]\n",
      "Epoch(Evaluation) [92/100]: 100% 9/9 [00:00<00:00, 11.03batch/s, acc=1]    \n",
      "Epoch(Training) [93/100]: 100% 9/9 [00:01<00:00,  4.85batch/s, loss=0.0084] \n",
      "Epoch(Evaluation) [93/100]: 100% 9/9 [00:00<00:00, 11.71batch/s, acc=1]    \n",
      "Epoch(Training) [94/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.00844]\n",
      "Epoch(Evaluation) [94/100]: 100% 9/9 [00:00<00:00, 10.95batch/s, acc=1]    \n",
      "Epoch(Training) [95/100]: 100% 9/9 [00:01<00:00,  4.84batch/s, loss=0.0081] \n",
      "Epoch(Evaluation) [95/100]: 100% 9/9 [00:00<00:00, 10.97batch/s, acc=1]    \n",
      "Epoch(Training) [96/100]: 100% 9/9 [00:01<00:00,  4.86batch/s, loss=0.00807]\n",
      "Epoch(Evaluation) [96/100]: 100% 9/9 [00:00<00:00, 11.39batch/s, acc=1]    \n",
      "Epoch(Training) [97/100]: 100% 9/9 [00:01<00:00,  4.89batch/s, loss=0.00799]\n",
      "Epoch(Evaluation) [97/100]: 100% 9/9 [00:00<00:00, 10.87batch/s, acc=1]    \n",
      "Epoch(Training) [98/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.00798]\n",
      "Epoch(Evaluation) [98/100]: 100% 9/9 [00:00<00:00, 11.01batch/s, acc=1]    \n",
      "Epoch(Training) [99/100]: 100% 9/9 [00:01<00:00,  4.83batch/s, loss=0.00806]\n",
      "Epoch(Evaluation) [99/100]: 100% 9/9 [00:00<00:00, 11.72batch/s, acc=1]    \n",
      "Epoch(Training) [100/100]: 100% 9/9 [00:01<00:00,  4.86batch/s, loss=0.00731] \n",
      "Epoch(Evaluation) [100/100]: 100% 9/9 [00:00<00:00, 10.93batch/s, acc=1]    \n"
     ]
    }
   ],
   "source": [
    "LR = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), LR)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_len = 0.\n",
    "    acc_num = 0\n",
    "    with tqdm(data_loader, unit = 'batch', ncols = 0, total = len(data_loader)) as tepoch:\n",
    "        for data, target in tepoch:\n",
    "            tepoch.set_description(f\"Epoch(Training) [{epoch + 1}/{100}]\")\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            pres = model(data)\n",
    "            loss = criterion(pres, target)\n",
    "            loss = loss.cuda()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_len += len(pres)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted = (pres == pres.max(dim=1, keepdim=True)[0]).to(dtype=torch.float32)\n",
    "            \n",
    "            tepoch.set_postfix(loss = running_loss)\n",
    "            \n",
    "    with tqdm(data_loader_eva, unit = 'batch', ncols = 0, total = len(data_loader_eva)) as tepoch:\n",
    "        for data, target in tepoch:\n",
    "            tepoch.set_description(f\"Epoch(Evaluation) [{epoch + 1}/{100}]\")\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            pres = model(data)\n",
    "\n",
    "            predicted = (pres == pres.max(dim=1, keepdim=True)[0]).to(dtype=torch.float32)\n",
    "            \n",
    "            acc_num = acc_num + torch.sum(torch.sum(predicted == target, dim = 1) / 4).item()\n",
    "            \n",
    "            accuracy = acc_num / running_len\n",
    "            \n",
    "            tepoch.set_postfix(acc = accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6982c02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5d2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
