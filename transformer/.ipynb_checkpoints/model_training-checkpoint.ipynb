{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24dd68f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT(\n",
      "  (to_patch_embedding): Sequential(\n",
      "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=32, p2=1)\n",
      "    (1): Linear(in_features=96, out_features=1024, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (transformer): Transformer(\n",
      "    (layers): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=8, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Linear(in_features=8, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=8, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Linear(in_features=8, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=8, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Linear(in_features=8, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=8, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Linear(in_features=8, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=8, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Linear(in_features=8, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (1): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=8, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Linear(in_features=8, out_features=1024, bias=True)\n",
      "              (4): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (to_latent): Identity()\n",
      "  (mlp_head): Sequential(\n",
      "    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=1024, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from vit_pytorch import ViT\n",
    "\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "\n",
    "\n",
    "model = ViT(\n",
    "    image_size = 512,    # 图像大小\n",
    "    patch_size = 32,     # patch大小（分块的大小）\n",
    "    num_classes = 4,  # imagenet数据集1000分类\n",
    "    dim = 1024,          # position embedding的维度\n",
    "    depth = 6,           # encoder和decoder中block层数是6\n",
    "    heads = 16,          # multi-head中head的数量为16\n",
    "    mlp_dim = 8,\n",
    "    dropout = 0.1,       # \n",
    "    emb_dropout = 0.1\n",
    ")\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "# img = torch.randn(1, 3, 256, 1)\n",
    "\n",
    "# preds = model(img) # (1, 1000)\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
    "print(model)  # (16, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a19636a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from data_extractor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13be733c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<data_extractor.Extractor at 0x7ff2a20f94c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Extractor('A01T')\n",
    "Extractor('A02T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f451c892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhz/experiment-BCI/transformer/../data_extractor.py:125: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  return torch.tensor(labels), torch.tensor(data)\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_eeg('A01T')\n",
    "labels, train_data = data_normalization(raw_data)\n",
    "raw_data_eva = load_eeg('A02T')\n",
    "labels_eva, eva_data = data_normalization(raw_data_eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f7d485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of labels is: torch.Size([288, 4]) shape of data is: torch.Size([288, 3, 512, 1])\n",
      "shape of labels is: torch.Size([288, 4]) shape of data is: torch.Size([288, 3, 512, 1])\n"
     ]
    }
   ],
   "source": [
    "print('shape of labels is:', labels.shape, 'shape of data is:', train_data.shape)\n",
    "print('shape of labels is:', labels_eva.shape, 'shape of data is:', eva_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "183982c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pres = model(train_data.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab29c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef560a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    # 构造函数\n",
    "    def __init__(self, data_tensor, target_tensor):\n",
    "        self.data_tensor = data_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "    # 返回数据集大小\n",
    "    def __len__(self):\n",
    "        return self.data_tensor.size(0)\n",
    "    # 返回索引的数据与标签\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_tensor[index], self.target_tensor[index]\n",
    "    \n",
    "dataset = MyDataset(train_data, labels)\n",
    "BATCH_SIZE = 32\n",
    "data_loader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "dataset_eva = MyDataset(eva_data, labels_eva)\n",
    "data_loader_eva = DataLoader(dataset_eva, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "673c06aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch(Training) [1/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=2.73]\n",
      "Epoch(Evaluation) [1/100]: 100% 9/9 [00:00<00:00, 13.16batch/s, acc=1]    \n",
      "Epoch(Training) [2/100]: 100% 9/9 [00:01<00:00,  5.69batch/s, loss=0.528]\n",
      "Epoch(Evaluation) [2/100]: 100% 9/9 [00:00<00:00, 13.03batch/s, acc=1]    \n",
      "Epoch(Training) [3/100]: 100% 9/9 [00:01<00:00,  5.66batch/s, loss=0.3]   \n",
      "Epoch(Evaluation) [3/100]: 100% 9/9 [00:00<00:00, 13.02batch/s, acc=1]    \n",
      "Epoch(Training) [4/100]: 100% 9/9 [00:01<00:00,  5.68batch/s, loss=0.213] \n",
      "Epoch(Evaluation) [4/100]: 100% 9/9 [00:00<00:00, 12.94batch/s, acc=1]    \n",
      "Epoch(Training) [5/100]: 100% 9/9 [00:01<00:00,  5.66batch/s, loss=0.162] \n",
      "Epoch(Evaluation) [5/100]: 100% 9/9 [00:00<00:00, 13.10batch/s, acc=1]    \n",
      "Epoch(Training) [6/100]: 100% 9/9 [00:01<00:00,  5.67batch/s, loss=0.138] \n",
      "Epoch(Evaluation) [6/100]: 100% 9/9 [00:00<00:00, 13.14batch/s, acc=1]    \n",
      "Epoch(Training) [7/100]: 100% 9/9 [00:01<00:00,  5.66batch/s, loss=0.114] \n",
      "Epoch(Evaluation) [7/100]: 100% 9/9 [00:00<00:00, 13.21batch/s, acc=1]    \n",
      "Epoch(Training) [8/100]: 100% 9/9 [00:01<00:00,  5.66batch/s, loss=0.0968]\n",
      "Epoch(Evaluation) [8/100]: 100% 9/9 [00:00<00:00, 13.25batch/s, acc=1]    \n",
      "Epoch(Training) [9/100]: 100% 9/9 [00:01<00:00,  5.66batch/s, loss=0.0883]\n",
      "Epoch(Evaluation) [9/100]: 100% 9/9 [00:00<00:00, 13.24batch/s, acc=1]    \n",
      "Epoch(Training) [10/100]: 100% 9/9 [00:01<00:00,  5.69batch/s, loss=0.0763]\n",
      "Epoch(Evaluation) [10/100]: 100% 9/9 [00:00<00:00, 13.08batch/s, acc=1]    \n",
      "Epoch(Training) [11/100]: 100% 9/9 [00:01<00:00,  5.67batch/s, loss=0.0683]\n",
      "Epoch(Evaluation) [11/100]: 100% 9/9 [00:00<00:00, 13.02batch/s, acc=1]    \n",
      "Epoch(Training) [12/100]: 100% 9/9 [00:01<00:00,  5.66batch/s, loss=0.0663]\n",
      "Epoch(Evaluation) [12/100]: 100% 9/9 [00:00<00:00, 13.02batch/s, acc=1]    \n",
      "Epoch(Training) [13/100]: 100% 9/9 [00:01<00:00,  5.64batch/s, loss=0.0579]\n",
      "Epoch(Evaluation) [13/100]: 100% 9/9 [00:00<00:00, 13.13batch/s, acc=1]    \n",
      "Epoch(Training) [14/100]: 100% 9/9 [00:01<00:00,  5.63batch/s, loss=0.0558]\n",
      "Epoch(Evaluation) [14/100]: 100% 9/9 [00:00<00:00, 13.07batch/s, acc=1]    \n",
      "Epoch(Training) [15/100]: 100% 9/9 [00:01<00:00,  5.63batch/s, loss=0.0523]\n",
      "Epoch(Evaluation) [15/100]: 100% 9/9 [00:00<00:00, 12.95batch/s, acc=1]    \n",
      "Epoch(Training) [16/100]: 100% 9/9 [00:01<00:00,  5.63batch/s, loss=0.0472]\n",
      "Epoch(Evaluation) [16/100]: 100% 9/9 [00:00<00:00, 12.99batch/s, acc=1]    \n",
      "Epoch(Training) [17/100]: 100% 9/9 [00:01<00:00,  5.66batch/s, loss=0.0453]\n",
      "Epoch(Evaluation) [17/100]: 100% 9/9 [00:00<00:00, 12.86batch/s, acc=1]    \n",
      "Epoch(Training) [18/100]: 100% 9/9 [00:01<00:00,  5.65batch/s, loss=0.0413] \n",
      "Epoch(Evaluation) [18/100]: 100% 9/9 [00:00<00:00, 12.94batch/s, acc=1]    \n",
      "Epoch(Training) [19/100]: 100% 9/9 [00:01<00:00,  5.65batch/s, loss=0.041]  \n",
      "Epoch(Evaluation) [19/100]: 100% 9/9 [00:00<00:00, 12.81batch/s, acc=1]    \n",
      "Epoch(Training) [20/100]: 100% 9/9 [00:01<00:00,  5.63batch/s, loss=0.0377] \n",
      "Epoch(Evaluation) [20/100]: 100% 9/9 [00:00<00:00, 12.93batch/s, acc=1]    \n",
      "Epoch(Training) [21/100]: 100% 9/9 [00:01<00:00,  5.64batch/s, loss=0.0356] \n",
      "Epoch(Evaluation) [21/100]: 100% 9/9 [00:00<00:00, 12.97batch/s, acc=1]    \n",
      "Epoch(Training) [22/100]: 100% 9/9 [00:01<00:00,  5.65batch/s, loss=0.0344] \n",
      "Epoch(Evaluation) [22/100]: 100% 9/9 [00:00<00:00, 12.86batch/s, acc=1]    \n",
      "Epoch(Training) [23/100]: 100% 9/9 [00:01<00:00,  5.64batch/s, loss=0.0329] \n",
      "Epoch(Evaluation) [23/100]: 100% 9/9 [00:00<00:00, 12.95batch/s, acc=1]    \n",
      "Epoch(Training) [24/100]: 100% 9/9 [00:01<00:00,  5.64batch/s, loss=0.0319] \n",
      "Epoch(Evaluation) [24/100]: 100% 9/9 [00:00<00:00, 12.95batch/s, acc=1]    \n",
      "Epoch(Training) [25/100]: 100% 9/9 [00:01<00:00,  5.64batch/s, loss=0.0306] \n",
      "Epoch(Evaluation) [25/100]: 100% 9/9 [00:00<00:00, 12.98batch/s, acc=1]    \n",
      "Epoch(Training) [26/100]: 100% 9/9 [00:01<00:00,  5.65batch/s, loss=0.0293] \n",
      "Epoch(Evaluation) [26/100]: 100% 9/9 [00:00<00:00, 12.88batch/s, acc=1]    \n",
      "Epoch(Training) [27/100]: 100% 9/9 [00:01<00:00,  5.64batch/s, loss=0.0276] \n",
      "Epoch(Evaluation) [27/100]: 100% 9/9 [00:00<00:00, 12.94batch/s, acc=1]    \n",
      "Epoch(Training) [28/100]: 100% 9/9 [00:01<00:00,  5.61batch/s, loss=0.0266] \n",
      "Epoch(Evaluation) [28/100]: 100% 9/9 [00:00<00:00, 12.92batch/s, acc=1]    \n",
      "Epoch(Training) [29/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.0255] \n",
      "Epoch(Evaluation) [29/100]: 100% 9/9 [00:00<00:00, 12.86batch/s, acc=1]    \n",
      "Epoch(Training) [30/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.0252] \n",
      "Epoch(Evaluation) [30/100]: 100% 9/9 [00:00<00:00, 12.84batch/s, acc=1]    \n",
      "Epoch(Training) [31/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.025]  \n",
      "Epoch(Evaluation) [31/100]: 100% 9/9 [00:00<00:00, 12.89batch/s, acc=1]    \n",
      "Epoch(Training) [32/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0235] \n",
      "Epoch(Evaluation) [32/100]: 100% 9/9 [00:00<00:00, 12.84batch/s, acc=1]    \n",
      "Epoch(Training) [33/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0228] \n",
      "Epoch(Evaluation) [33/100]: 100% 9/9 [00:00<00:00, 12.88batch/s, acc=1]    \n",
      "Epoch(Training) [34/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.0218] \n",
      "Epoch(Evaluation) [34/100]: 100% 9/9 [00:00<00:00, 12.85batch/s, acc=1]    \n",
      "Epoch(Training) [35/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0214] \n",
      "Epoch(Evaluation) [35/100]: 100% 9/9 [00:00<00:00, 12.87batch/s, acc=1]    \n",
      "Epoch(Training) [36/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.0206] \n",
      "Epoch(Evaluation) [36/100]: 100% 9/9 [00:00<00:00, 12.85batch/s, acc=1]    \n",
      "Epoch(Training) [37/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0205] \n",
      "Epoch(Evaluation) [37/100]: 100% 9/9 [00:00<00:00, 12.88batch/s, acc=1]    \n",
      "Epoch(Training) [38/100]: 100% 9/9 [00:01<00:00,  5.61batch/s, loss=0.02]   \n",
      "Epoch(Evaluation) [38/100]: 100% 9/9 [00:00<00:00, 12.81batch/s, acc=1]    \n",
      "Epoch(Training) [39/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.019]  \n",
      "Epoch(Evaluation) [39/100]: 100% 9/9 [00:00<00:00, 12.89batch/s, acc=1]    \n",
      "Epoch(Training) [40/100]: 100% 9/9 [00:01<00:00,  5.61batch/s, loss=0.0189] \n",
      "Epoch(Evaluation) [40/100]: 100% 9/9 [00:00<00:00, 12.74batch/s, acc=1]    \n",
      "Epoch(Training) [41/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.0189] \n",
      "Epoch(Evaluation) [41/100]: 100% 9/9 [00:00<00:00, 12.88batch/s, acc=1]    \n",
      "Epoch(Training) [42/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0181] \n",
      "Epoch(Evaluation) [42/100]: 100% 9/9 [00:00<00:00, 12.85batch/s, acc=1]    \n",
      "Epoch(Training) [43/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0181] \n",
      "Epoch(Evaluation) [43/100]: 100% 9/9 [00:00<00:00, 12.93batch/s, acc=1]    \n",
      "Epoch(Training) [44/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0176] \n",
      "Epoch(Evaluation) [44/100]: 100% 9/9 [00:00<00:00, 12.89batch/s, acc=1]    \n",
      "Epoch(Training) [45/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0172] \n",
      "Epoch(Evaluation) [45/100]: 100% 9/9 [00:00<00:00, 12.88batch/s, acc=1]    \n",
      "Epoch(Training) [46/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0163] \n",
      "Epoch(Evaluation) [46/100]: 100% 9/9 [00:00<00:00, 12.90batch/s, acc=1]    \n",
      "Epoch(Training) [47/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.0159] \n",
      "Epoch(Evaluation) [47/100]: 100% 9/9 [00:00<00:00, 12.88batch/s, acc=1]    \n",
      "Epoch(Training) [48/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.0165] \n",
      "Epoch(Evaluation) [48/100]: 100% 9/9 [00:00<00:00, 12.89batch/s, acc=1]    \n",
      "Epoch(Training) [49/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0161] \n",
      "Epoch(Evaluation) [49/100]: 100% 9/9 [00:00<00:00, 12.90batch/s, acc=1]    \n",
      "Epoch(Training) [50/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.015]  \n",
      "Epoch(Evaluation) [50/100]: 100% 9/9 [00:00<00:00, 12.86batch/s, acc=1]    \n",
      "Epoch(Training) [51/100]: 100% 9/9 [00:01<00:00,  5.58batch/s, loss=0.0154] \n",
      "Epoch(Evaluation) [51/100]: 100% 9/9 [00:00<00:00, 12.92batch/s, acc=1]    \n",
      "Epoch(Training) [52/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0141] \n",
      "Epoch(Evaluation) [52/100]: 100% 9/9 [00:00<00:00, 12.90batch/s, acc=1]    \n",
      "Epoch(Training) [53/100]: 100% 9/9 [00:01<00:00,  5.61batch/s, loss=0.014]  \n",
      "Epoch(Evaluation) [53/100]: 100% 9/9 [00:00<00:00, 12.82batch/s, acc=1]    \n",
      "Epoch(Training) [54/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.0141] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch(Evaluation) [54/100]: 100% 9/9 [00:00<00:00, 12.90batch/s, acc=1]    \n",
      "Epoch(Training) [55/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0136] \n",
      "Epoch(Evaluation) [55/100]: 100% 9/9 [00:00<00:00, 12.91batch/s, acc=1]    \n",
      "Epoch(Training) [56/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0133] \n",
      "Epoch(Evaluation) [56/100]: 100% 9/9 [00:00<00:00, 12.90batch/s, acc=1]    \n",
      "Epoch(Training) [57/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.0132] \n",
      "Epoch(Evaluation) [57/100]: 100% 9/9 [00:00<00:00, 12.89batch/s, acc=1]    \n",
      "Epoch(Training) [58/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.0133] \n",
      "Epoch(Evaluation) [58/100]: 100% 9/9 [00:00<00:00, 12.85batch/s, acc=1]    \n",
      "Epoch(Training) [59/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0128] \n",
      "Epoch(Evaluation) [59/100]: 100% 9/9 [00:00<00:00, 12.95batch/s, acc=1]    \n",
      "Epoch(Training) [60/100]: 100% 9/9 [00:01<00:00,  5.61batch/s, loss=0.0125] \n",
      "Epoch(Evaluation) [60/100]: 100% 9/9 [00:00<00:00, 12.78batch/s, acc=1]    \n",
      "Epoch(Training) [61/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0123] \n",
      "Epoch(Evaluation) [61/100]: 100% 9/9 [00:00<00:00, 12.92batch/s, acc=1]    \n",
      "Epoch(Training) [62/100]: 100% 9/9 [00:01<00:00,  5.62batch/s, loss=0.0121] \n",
      "Epoch(Evaluation) [62/100]: 100% 9/9 [00:00<00:00, 12.79batch/s, acc=1]    \n",
      "Epoch(Training) [63/100]: 100% 9/9 [00:01<00:00,  5.61batch/s, loss=0.0121] \n",
      "Epoch(Evaluation) [63/100]: 100% 9/9 [00:00<00:00, 12.79batch/s, acc=1]    \n",
      "Epoch(Training) [64/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.0121] \n",
      "Epoch(Evaluation) [64/100]: 100% 9/9 [00:00<00:00, 12.85batch/s, acc=1]    \n",
      "Epoch(Training) [65/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0117] \n",
      "Epoch(Evaluation) [65/100]: 100% 9/9 [00:00<00:00, 12.90batch/s, acc=1]    \n",
      "Epoch(Training) [66/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0117] \n",
      "Epoch(Evaluation) [66/100]: 100% 9/9 [00:00<00:00, 12.93batch/s, acc=1]    \n",
      "Epoch(Training) [67/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.0113] \n",
      "Epoch(Evaluation) [67/100]: 100% 9/9 [00:00<00:00, 12.91batch/s, acc=1]    \n",
      "Epoch(Training) [68/100]: 100% 9/9 [00:01<00:00,  5.58batch/s, loss=0.0112] \n",
      "Epoch(Evaluation) [68/100]: 100% 9/9 [00:00<00:00, 12.91batch/s, acc=1]    \n",
      "Epoch(Training) [69/100]: 100% 9/9 [00:01<00:00,  5.61batch/s, loss=0.0109] \n",
      "Epoch(Evaluation) [69/100]: 100% 9/9 [00:00<00:00, 12.82batch/s, acc=1]    \n",
      "Epoch(Training) [70/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0106] \n",
      "Epoch(Evaluation) [70/100]: 100% 9/9 [00:00<00:00, 12.92batch/s, acc=1]    \n",
      "Epoch(Training) [71/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.0109] \n",
      "Epoch(Evaluation) [71/100]: 100% 9/9 [00:00<00:00, 12.90batch/s, acc=1]    \n",
      "Epoch(Training) [72/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0107] \n",
      "Epoch(Evaluation) [72/100]: 100% 9/9 [00:00<00:00, 12.92batch/s, acc=1]    \n",
      "Epoch(Training) [73/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.0105] \n",
      "Epoch(Evaluation) [73/100]: 100% 9/9 [00:00<00:00, 12.92batch/s, acc=1]    \n",
      "Epoch(Training) [74/100]: 100% 9/9 [00:01<00:00,  5.61batch/s, loss=0.01]   \n",
      "Epoch(Evaluation) [74/100]: 100% 9/9 [00:00<00:00, 12.78batch/s, acc=1]    \n",
      "Epoch(Training) [75/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00998]\n",
      "Epoch(Evaluation) [75/100]: 100% 9/9 [00:00<00:00, 12.92batch/s, acc=1]    \n",
      "Epoch(Training) [76/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00996]\n",
      "Epoch(Evaluation) [76/100]: 100% 9/9 [00:00<00:00, 12.90batch/s, acc=1]    \n",
      "Epoch(Training) [77/100]: 100% 9/9 [00:01<00:00,  5.61batch/s, loss=0.00993]\n",
      "Epoch(Evaluation) [77/100]: 100% 9/9 [00:00<00:00, 12.79batch/s, acc=1]    \n",
      "Epoch(Training) [78/100]: 100% 9/9 [00:01<00:00,  5.58batch/s, loss=0.0098] \n",
      "Epoch(Evaluation) [78/100]: 100% 9/9 [00:00<00:00, 12.90batch/s, acc=1]    \n",
      "Epoch(Training) [79/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.00967]\n",
      "Epoch(Evaluation) [79/100]: 100% 9/9 [00:00<00:00, 12.87batch/s, acc=1]    \n",
      "Epoch(Training) [80/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00951]\n",
      "Epoch(Evaluation) [80/100]: 100% 9/9 [00:00<00:00, 12.94batch/s, acc=1]    \n",
      "Epoch(Training) [81/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.00929]\n",
      "Epoch(Evaluation) [81/100]: 100% 9/9 [00:00<00:00, 12.87batch/s, acc=1]    \n",
      "Epoch(Training) [82/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00923]\n",
      "Epoch(Evaluation) [82/100]: 100% 9/9 [00:00<00:00, 12.94batch/s, acc=1]    \n",
      "Epoch(Training) [83/100]: 100% 9/9 [00:01<00:00,  5.61batch/s, loss=0.00924]\n",
      "Epoch(Evaluation) [83/100]: 100% 9/9 [00:00<00:00, 12.76batch/s, acc=1]    \n",
      "Epoch(Training) [84/100]: 100% 9/9 [00:01<00:00,  5.60batch/s, loss=0.00876]\n",
      "Epoch(Evaluation) [84/100]: 100% 9/9 [00:00<00:00, 12.89batch/s, acc=1]    \n",
      "Epoch(Training) [85/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00893]\n",
      "Epoch(Evaluation) [85/100]: 100% 9/9 [00:00<00:00, 12.90batch/s, acc=1]    \n",
      "Epoch(Training) [86/100]: 100% 9/9 [00:01<00:00,  5.58batch/s, loss=0.00872]\n",
      "Epoch(Evaluation) [86/100]: 100% 9/9 [00:00<00:00, 12.89batch/s, acc=1]    \n",
      "Epoch(Training) [87/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00836]\n",
      "Epoch(Evaluation) [87/100]: 100% 9/9 [00:00<00:00, 12.93batch/s, acc=1]    \n",
      "Epoch(Training) [88/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00864]\n",
      "Epoch(Evaluation) [88/100]: 100% 9/9 [00:00<00:00, 12.89batch/s, acc=1]    \n",
      "Epoch(Training) [89/100]: 100% 9/9 [00:01<00:00,  5.58batch/s, loss=0.00849]\n",
      "Epoch(Evaluation) [89/100]: 100% 9/9 [00:00<00:00, 12.92batch/s, acc=1]    \n",
      "Epoch(Training) [90/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00832]\n",
      "Epoch(Evaluation) [90/100]: 100% 9/9 [00:00<00:00, 12.92batch/s, acc=1]    \n",
      "Epoch(Training) [91/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00815]\n",
      "Epoch(Evaluation) [91/100]: 100% 9/9 [00:00<00:00, 12.92batch/s, acc=1]    \n",
      "Epoch(Training) [92/100]: 100% 9/9 [00:01<00:00,  5.61batch/s, loss=0.00841]\n",
      "Epoch(Evaluation) [92/100]: 100% 9/9 [00:00<00:00, 12.84batch/s, acc=1]    \n",
      "Epoch(Training) [93/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00842]\n",
      "Epoch(Evaluation) [93/100]: 100% 9/9 [00:00<00:00, 12.90batch/s, acc=1]    \n",
      "Epoch(Training) [94/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00835]\n",
      "Epoch(Evaluation) [94/100]: 100% 9/9 [00:00<00:00, 12.90batch/s, acc=1]    \n",
      "Epoch(Training) [95/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00816]\n",
      "Epoch(Evaluation) [95/100]: 100% 9/9 [00:00<00:00, 12.91batch/s, acc=1]    \n",
      "Epoch(Training) [96/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00785]\n",
      "Epoch(Evaluation) [96/100]: 100% 9/9 [00:00<00:00, 12.89batch/s, acc=1]    \n",
      "Epoch(Training) [97/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00775]\n",
      "Epoch(Evaluation) [97/100]: 100% 9/9 [00:00<00:00, 12.90batch/s, acc=1]    \n",
      "Epoch(Training) [98/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00786]\n",
      "Epoch(Evaluation) [98/100]: 100% 9/9 [00:00<00:00, 12.94batch/s, acc=1]    \n",
      "Epoch(Training) [99/100]: 100% 9/9 [00:01<00:00,  5.58batch/s, loss=0.00762]\n",
      "Epoch(Evaluation) [99/100]: 100% 9/9 [00:00<00:00, 12.90batch/s, acc=1]    \n",
      "Epoch(Training) [100/100]: 100% 9/9 [00:01<00:00,  5.59batch/s, loss=0.00772]\n",
      "Epoch(Evaluation) [100/100]: 100% 9/9 [00:00<00:00, 12.89batch/s, acc=1]    \n"
     ]
    }
   ],
   "source": [
    "LR = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), LR)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_len = 0.\n",
    "    acc_num = 0\n",
    "    with tqdm(data_loader, unit = 'batch', ncols = 0, total = len(data_loader)) as tepoch:\n",
    "        for data, target in tepoch:\n",
    "            tepoch.set_description(f\"Epoch(Training) [{epoch + 1}/{100}]\")\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            pres = model(data)\n",
    "            loss = criterion(pres, target)\n",
    "            loss = loss.cuda()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_len += len(pres)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted = (pres == pres.max(dim=1, keepdim=True)[0]).to(dtype=torch.float32)\n",
    "            \n",
    "            tepoch.set_postfix(loss = running_loss)\n",
    "            \n",
    "    model.eval()\n",
    "    with tqdm(data_loader_eva, unit = 'batch', ncols = 0, total = len(data_loader_eva)) as tepoch:\n",
    "        for data, target in tepoch:\n",
    "            tepoch.set_description(f\"Epoch(Evaluation) [{epoch + 1}/{100}]\")\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            pres = model(data)\n",
    "\n",
    "            predicted = (pres == pres.max(dim=1, keepdim=True)[0]).to(dtype=torch.float32)\n",
    "            \n",
    "            acc_num = acc_num + torch.sum(torch.sum(predicted == target, dim = 1) / 4).item()\n",
    "            \n",
    "            accuracy = acc_num / running_len\n",
    "            \n",
    "            tepoch.set_postfix(acc = accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6982c02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5d2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
